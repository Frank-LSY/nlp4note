{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import jsonlines\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## paths\n",
    "emb_dir = \"/Users/weiw2/Temp/hf/data/embs\"\n",
    "txt_dir = \"/Users/weiw2/Temp/hf/classified_txt/\"\n",
    "label_file = \"/Users/weiw2/Temp/hf/data/ef_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load embeddings\n",
    "def load_avg_doc_embs(infile):\n",
    "    \"\"\"\n",
    "        Get the CLS embedding of the last layer\n",
    "        typically, the doc length is longer than the max_seq_len, e.g., 128\n",
    "    \"\"\"\n",
    "    with open(infile) as fin:\n",
    "        json = jsonlines.Reader(fin)\n",
    "        all_cls_embs = []\n",
    "        for line in json: ## a line is a chunk of the max_seq_length from this doc\n",
    "            feats = line['features']\n",
    "            feat_cls = feats[0] # [CLS] \n",
    "            final_layer = feat_cls['layers'][0]['values'] ## [CLS] embedding\n",
    "            all_cls_embs.append(final_layer)\n",
    "    ## get the mean of cls embeddings of all chunks from this doc\n",
    "    all_cls_embs_tensor = torch.tensor(all_cls_embs)\n",
    "    avg_doc_emb = torch.mean(all_cls_embs_tensor, dim=0)\n",
    "    return avg_doc_emb\n",
    "\n",
    "def get_pt_avg_emb(inpt_dir):\n",
    "    docs = os.listdir(pid_dir)\n",
    "    doc_num = len(docs)\n",
    "    emb_dim = 768 ## hard coded. change it\n",
    "    pt_all_embs_tensor = torch.zeros(doc_num, emb_dim)\n",
    "    for idx in range(doc_num):\n",
    "        emb_file = docs[idx]\n",
    "        avg_doc_emb = load_avg_doc_embs(os.path.join(pid_dir, emb_file))\n",
    "        pt_all_embs_tensor[idx] = avg_doc_emb\n",
    "    return pt_all_embs_tensor\n",
    "\n",
    "pt_emb_dict = {}\n",
    "for src in os.listdir(emb_dir):\n",
    "    src_dir = os.path.join(emb_dir, src)\n",
    "    for pid in os.listdir(src_dir):\n",
    "        pid_dir = os.path.join(src_dir, pid)\n",
    "        pt_avg_emb = get_pt_avg_emb(pid_dir)\n",
    "        pt_emb_dict[pid] = pt_avg_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## avg pt_emb_dict\n",
    "for k, v in pt_emb_dict.items():\n",
    "    pt_emb_dict[k] = torch.mean(v, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/weiw2/Temp/hf/data/embs/NOTES-AMBULATORY_VISIT_SUMMARY/1220001226/20160923.jsonl\") as fin:\n",
    "    json = jsonlines.Reader(fin)\n",
    "    for line in json:\n",
    "        feats = line['features']\n",
    "        feat_cls = feats[0] # [CLS]\n",
    "        final_layer = feat_cls['layers'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130774, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>STUDY_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>71.7</td>\n",
       "      <td>20171207</td>\n",
       "      <td>1221820821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20140228</td>\n",
       "      <td>1221176058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>20140618</td>\n",
       "      <td>1221176058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20150605</td>\n",
       "      <td>1221748761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20151218</td>\n",
       "      <td>1221748761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  VALUE      DATE    STUDY_ID\n",
       "0   1   71.7  20171207  1221820821\n",
       "1   2   35.0  20140228  1221176058\n",
       "2   3   55.0  20140618  1221176058\n",
       "3   4   45.0  20150605  1221748761\n",
       "4   5   45.0  20151218  1221748761"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load labels\n",
    "label_df = pd.read_csv(label_file)\n",
    "print(label_df.shape)\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>STUDY_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUDY_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1220000159</th>\n",
       "      <td>113646</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20180606</td>\n",
       "      <td>1220000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220000216</th>\n",
       "      <td>28359</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20170113</td>\n",
       "      <td>1220000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220000416</th>\n",
       "      <td>52434</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20160902</td>\n",
       "      <td>1220000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220001054</th>\n",
       "      <td>92809</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20180315</td>\n",
       "      <td>1220001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220001226</th>\n",
       "      <td>13344</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20161127</td>\n",
       "      <td>1220001226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  VALUE      DATE    STUDY_ID\n",
       "STUDY_ID                                       \n",
       "1220000159  113646   35.0  20180606  1220000159\n",
       "1220000216   28359   65.0  20170113  1220000216\n",
       "1220000416   52434   45.0  20160902  1220000416\n",
       "1220001054   92809   15.0  20180315  1220001054\n",
       "1220001226   13344   35.0  20161127  1220001226"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_df = pd.DataFrame([int(id_) for id_ in list(pt_emb_dict.keys())], columns=[\"Patient_ID\"])\n",
    "sub_label_df = pd.merge(label_df, pts_df, left_on=\"STUDY_ID\", right_on=\"Patient_ID\")[label_df.columns]\n",
    "\n",
    "\n",
    "def find_latest(x):\n",
    "    x = x.sort_values(by='DATE', ascending=False)\n",
    "    x = x.iloc[0,:]\n",
    "    return x\n",
    "\n",
    "sub_label_df = sub_label_df.groupby(\"STUDY_ID\").apply(find_latest)\n",
    "sub_label_df = sub_label_df.astype({\"ID\": int, \"VALUE\": float, \"DATE\": int, \"STUDY_ID\": int})\n",
    "sub_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make label dict\n",
    "pt_label_dict = {}\n",
    "for pid in pt_emb_dict.keys():\n",
    "    label = sub_label_df[sub_label_df[\"STUDY_ID\"]==int(pid)]['VALUE'].tolist()\n",
    "    if len(label) > 0:\n",
    "        pt_label_dict[int(pid)] = float(label[0])\n",
    "len(pt_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make embedding tensor and label tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "## regression\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.i2o = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.i2o(inputs)\n",
    "        return output    \n",
    "    \n",
    "pt_dim = 768\n",
    "out_dim = 1\n",
    "model = Model(pt_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimizer\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target):    \n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_tensor)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()        \n",
    "    return output, loss.item() / input_line_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target):    \n",
    "    optimizer.zero_grad()\n",
    "    for pt, input_tensor in range(len(input_dict)):\n",
    "        target = label_dict.get(pt)\n",
    "        output = model(input_tensor)\n",
    "        loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    return output, loss.item() / input_line_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_iters = 100\n",
    "# plot_every = 10\n",
    "# start = time.time()\n",
    "\n",
    "# # Keep track of losses for plotting\n",
    "# current_loss = 0\n",
    "# all_losses = []\n",
    "\n",
    "\n",
    "\n",
    "# # len(pt_emb_dict), len(pt_label_dict)\n",
    "\n",
    "# # for epic_idx in range(1, n_iters + 1):\n",
    "    \n",
    "# for pt, target in pt_label_dict.items():\n",
    "#     input_tensor = pt_emb_dict.get(str(pt)) # torch.Size([768])\n",
    "#     input_tensor = input_tensor.view(1, 1, -1)\n",
    "#     target = torch.tensor([target], dtype=torch.long)\n",
    "#     target = target.view(1, -1)\n",
    "#     print(target.size())\n",
    "#     output, loss = train(input_tensor, target)\n",
    "#     current_loss += loss    \n",
    "    \n",
    "# #     output, loss = train()\n",
    "    \n",
    "    \n",
    "# #     category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "# #     output, loss = train(category_tensor, line_tensor)\n",
    "# #     current_loss += loss\n",
    "\n",
    "# #     # Print iter number, loss, name and guess\n",
    "# #     if iter % print_every == 0:\n",
    "# #         guess, guess_i = categoryFromOutput(output)\n",
    "# #         correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "# #         print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "# #     # Add current loss avg to list of losses\n",
    "# #     if iter % plot_every == 0:\n",
    "# #         all_losses.append(current_loss / plot_every)\n",
    "# #         current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data[:150]\n",
    "y = diabetes.target[:150]\n",
    "lasso = linear_model.Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_label_dict\n",
    "pt_emb_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for pt, target in pt_label_dict.items():\n",
    "    y.append(target)\n",
    "    emb = pt_emb_dict.get(str(pt)).squeeze().numpy()\n",
    "    X.append(emb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 768)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19,)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10029695, -6.44376761, -0.09643739, -2.19514003, -0.47890627])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = cross_validate(lasso, X, y, cv=5)\n",
    "# sorted(cv_results.keys())\n",
    "cv_results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
